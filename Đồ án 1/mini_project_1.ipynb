{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4HT-e66tClHz"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_S3SxbXWez2W"
      },
      "outputs": [],
      "source": [
        "\n",
        "TONE_MARKS = {\n",
        "    \"\\u0301\": 5,  # sắc\n",
        "    \"\\u0300\": 2,  # huyền\n",
        "    \"\\u0303\": 3,  # ngã\n",
        "    \"\\u0309\": 4,  # hỏi\n",
        "    \"\\u0323\": 6,  # nặng\n",
        "}\n",
        "TONE_DEFAULT = 1  # ngang\n",
        "\n",
        "def strip_tone_and_get_number(word: str):\n",
        "    d = unicodedata.normalize(\"NFD\", word)\n",
        "    tone = None\n",
        "    out = []\n",
        "    for ch in d:\n",
        "        if unicodedata.combining(ch):\n",
        "            if ch in TONE_MARKS and tone is None:\n",
        "                tone = TONE_MARKS[ch]\n",
        "            else:\n",
        "                out.append(ch)\n",
        "        else:\n",
        "            out.append(ch)\n",
        "    if tone is None:\n",
        "        tone = TONE_DEFAULT\n",
        "    return unicodedata.normalize(\"NFC\", \"\".join(out)), tone\n",
        "\n",
        "PL_IE  = \"\\ue000\"  # iê/ia/yê -> ie\n",
        "PL_UO  = \"\\ue001\"  # uô/ua -> uo\n",
        "PL_UG  = \"\\ue002\"  # ươ/ưa -> ɯɤ\n",
        "PL_ECI = \"\\ue003\"  # ây -> ɤ̌i\n",
        "\n",
        "SEQ_RULES = [\n",
        "    (r\"ngh\", \"ŋ\"),\n",
        "    (r\"ng\",  \"ŋ\"),\n",
        "    (r\"gh\",  \"ɣ\"),\n",
        "    (r\"kh\",  \"χ\"),\n",
        "    (r\"ph\",  \"f\"),\n",
        "    (r\"th\",  \"tʰ\"),\n",
        "    (r\"tr\",  \"ʈ\"),\n",
        "    (r\"ch\",  \"C\"),\n",
        "    (r\"gi\",  \"z\"),\n",
        "    (r\"qu\",  \"kw\"),\n",
        "]\n",
        "\n",
        "DIPH_RULES = [\n",
        "    (r\"iê\", PL_IE), (r\"yê\", PL_IE), (r\"ia\", PL_IE),\n",
        "    (r\"uô\", PL_UO), (r\"ua\", PL_UO),\n",
        "    (r\"ươ\", PL_UG), (r\"ưa\", PL_UG),\n",
        "    (r\"ây\", PL_ECI),\n",
        "]\n",
        "\n",
        "VOW_PRE_RULES = [\n",
        "    (r\"ê\", \"E\"),\n",
        "    (r\"ô\", \"O\"),\n",
        "    (r\"ơ\", \"ɤ\"),\n",
        "    (r\"ư\", \"ɯ\"),\n",
        "    (r\"â\", \"ɤ̆\"),\n",
        "    (r\"ă\", \"ă\"),\n",
        "]\n",
        "\n",
        "CONS_SINGLE_RULES = [\n",
        "    (r\"b\", \"b\"),\n",
        "    (r\"c\", \"k\"),\n",
        "    (r\"k\", \"k\"),\n",
        "    (r\"q\", \"k\"),\n",
        "    (r\"đ\", \"D\"),\n",
        "    (r\"g\", \"ɣ\"),\n",
        "    (r\"h\", \"h\"),\n",
        "    (r\"l\", \"l\"),\n",
        "    (r\"m\", \"m\"),\n",
        "    (r\"n\", \"n\"),\n",
        "    (r\"p\", \"p\"),\n",
        "    (r\"r\", \"ʐ\"),\n",
        "    (r\"s\", \"ʂ\"),\n",
        "    (r\"t\", \"t\"),\n",
        "    (r\"v\", \"v\"),\n",
        "    (r\"x\", \"s\"),\n",
        "    (r\"d\", \"z\"),\n",
        "]\n",
        "\n",
        "VOW_FINAL_RULES = [\n",
        "    (r\"y\", \"i\"),\n",
        "    (r\"i\", \"i\"),\n",
        "    (r\"e\", \"ɛ\"),\n",
        "    (r\"o\", \"ɔ\"),\n",
        "    (r\"a\", \"a\"),\n",
        "    (r\"u\", \"u\"),\n",
        "]\n",
        "\n",
        "def apply_rules(s: str, rules):\n",
        "    for pat, rep in rules:\n",
        "        s = re.sub(pat, rep, s)\n",
        "    return s\n",
        "\n",
        "def convert_word_with_tone(token: str) -> str:\n",
        "    if not re.search(r\"\\w\", token, flags=re.UNICODE):\n",
        "        return token\n",
        "\n",
        "    base, tone = strip_tone_and_get_number(token)\n",
        "    s = base.lower()\n",
        "\n",
        "    s = apply_rules(s, DIPH_RULES)\n",
        "    s = apply_rules(s, SEQ_RULES)\n",
        "    s = apply_rules(s, VOW_PRE_RULES)\n",
        "    s = apply_rules(s, CONS_SINGLE_RULES)\n",
        "    s = apply_rules(s, VOW_FINAL_RULES)\n",
        "\n",
        "    s = (s.replace(\"C\", \"c\")\n",
        "           .replace(\"D\", \"d\")\n",
        "           .replace(\"E\", \"e\")\n",
        "           .replace(\"O\", \"o\"))\n",
        "\n",
        "\n",
        "\n",
        "    s = (s.replace(PL_IE,  \"ie\")\n",
        "           .replace(PL_UO,  \"uo\")\n",
        "           .replace(PL_UG,  \"ɯɤ\")\n",
        "           .replace(PL_ECI, \"ɤ̌i\"))\n",
        "\n",
        "    return f\"{s}{tone}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1lJjNYWkB70q"
      },
      "outputs": [],
      "source": [
        "def vn_to_phonemic(text: str) -> str:\n",
        "    tokens = re.findall(r\"\\w+|\\W+\", text, flags=re.UNICODE)\n",
        "    return \"\".join(\n",
        "        convert_word_with_tone(tok) if re.match(r\"^\\w+$\", tok, flags=re.UNICODE) else tok\n",
        "        for tok in tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BFycyqQae1at",
        "outputId": "e365c839-4d98-4e91-9c5a-89b555c2a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'neu5 biet5 ʐăŋ2 ɛm1 da3 kɔ5 coŋ2'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vn_to_phonemic(\"Nếu biết rằng em đã có chồng\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ʈɤi2 ɤi1 ŋɯɤi2 ɤ̌i5 kɔ5 buon2 χoŋ1'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vn_to_phonemic(\"trời ơi người ấy có buồn không\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'toi1 ieu1 ɛm1 den5 nai1 cɯŋ2 kɔ5 tʰe4. ŋɔn6 lɯɤ4 tinh2 cɯɤ1 hăn4 da3 tan2 fai1'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vn_to_phonemic(\"Tôi yêu em đến nay chừng có thể. Ngọn lửa tình chưa hẳn đã tàn phai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'tʰɤ̆n1 ɛm1 vɯɤ2 ʈăŋ5 lai6 vɯɤ2 ʈɔn2'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vn_to_phonemic(\"Thân em vừa trắng lại vừa tròn\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
